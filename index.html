<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Seung-Eun Kim</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />

		<!-- Google tag (gtag.js) -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=G-T1JS7YWYKR"></script>
		<script>
		  window.dataLayer = window.dataLayer || [];
		  function gtag(){dataLayer.push(arguments);}
		  gtag('js', new Date());

		  gtag('config', 'G-T1JS7YWYKR');
		</script>

	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<!-- <a href="index.html" class="logo"><strong>Editorial</strong> by HTML5 UP</a> -->
									<!-- <ul class="icons">
										<li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
										<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
										<li><a href="#" class="icon brands fa-snapchat-ghost"><span class="label">Snapchat</span></a></li>
										<li><a href="#" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
										<li><a href="#" class="icon brands fa-medium-m"><span class="label">Medium</span></a></li>
									</ul> -->
								</header>

							<!-- Banner -->
								<section id="banner">
									<div class="main">
										<header>
											<h1>Seung-Eun Kim</h1>
											<!-- <p> PhD in Linguistics, Cornell University</p> -->
										</header>
										<p> <font size = +1> I am a Postdoctoral Fellow in the <a href="https://linguistics.northwestern.edu/">Department of Linguistics </a> at Northwestern University.
											<!-- I am working with <a href="https://faculty.wcas.northwestern.edu/matt-goldrick/">Matt Goldrick</a> and
											<a href="https://faculty.wcas.northwestern.edu/ann-bradlow/">Ann Bradlow</a> on the NSF project titled
											<i> "Enhancing research on speech and deep learning through holistic acoustic analysis." </i> <br /> <br /> -->
											I am working with <a href="https://faculty.wcas.northwestern.edu/matt-goldrick/">Matt Goldrick</a> and
											<a href="https://faculty.wcas.northwestern.edu/ann-bradlow/">Ann Bradlow</a> on the NSF projects titled
											<i> "Enhancing research on speech and deep learning through holistic acoustic analysis"</i> and
											<i> "LangDiv: Talker-specific, language-specific, and language-general characteristics of first-language and second-language speech."</i> <br /> <br />
											I received my Ph.D. from the <a href="https://linguistics.cornell.edu/">Department of Linguistics</a> at Cornell University in December 2022
											and was advised by <a href="https://conf.ling.cornell.edu/~tilsen/">Sam Tilsen</a>.
											<!-- I was a member of the <a href="https://conf.ling.cornell.edu/">Cornell Phonetics Lab</a>. -->
										  I received my B.A. and M.A. from the Department of English Language & Literature at Yonsei University, South Korea. </font> </p>
										<p> contact: <a href = "mailto: seungeun.kim@northwestern.edu">seungeun.kim@northwestern.edu </a> </p>
										<ul class="actions">
											<li><a href="pdfs/CV_SK.pdf" class="button">CV</a></li>
										</ul>
									</div>
									<span class="image object">
										<center> <img src="images/photo_SK_original.JPG" style="width:70%" object-fit="cover" alt=""/> </center>
										<!-- style = "width: 440px; height: 550px"  -->
									</span>
								</section>


							<!-- Research Section -->
								<section>
									<header id = "research" class="main special">
										<h1>Research</h1>
									</header>
									<p> <font size = +1> I am interested in how speakers formulate and produce multi-phrase utterances and how listeners recognize them.
										During my Ph.D., I conducted research on speech planning and production, examining how articulatory movements and acoustic signals vary in relation to syntactic and prosodic structure.
										In my ongoing postdoctoral research, I am investigating intelligibility of connected speech, especially that produced by bilingual speakers.
										I utilize both experimental and computational methods in my research. <br /> <br />

										Below is a summary of some of my past and current projects. If you click on each figure, you will be directed to the most relevant publication (except for the ones that are under review).
										Please check out my <a href="pdfs/CV_SK.pdf">CV </a> for a full list of publications and presentations, and feel free to email me for any pdfs or slides/posters.
 										</font> </p> <br />


									<div class="posts">

										<!-- Research 1: PSSP -->
										<article>
											<a class="image"><img src="images/research_PSSP.png" alt="" /></a>
											<h3> Predicting relative intelligibility of second-language (L2) talkers using self-supervised representations </h3>
											<p> In this study, we modeled relative speech intelligibility of over 100 L2 English talkers, using a self-supervised learning model.
												For each recording, we obtained representations from a self-supervised model, which formed a trajectory in the perceptual similarity space. We found that the average distance of the trajectories
												of an L2 talker from the L1 talker group correlates with their intelligibility assessed by human L1 listeners.
												Notably, the distance measure predicted the relative intelligibility of L2 talkers more robustly than traditional acoustic-phonetic cues (e.g., speech rate, mean pitch).
												This study emphasizes the importance of <i>holistic</i> assessment of speech in modeling speech intelligibility. </p>
										</article>

										<!-- Research 2: ASR -->
										<article>
											<a href="https://pubs.aip.org/asa/jel/article/4/2/025204/3263708/Automatic-recognition-of-second-language-speech-in?searchresult=1" class="image"><img src="images/research_ASR.png" alt="" /></a>
											<h3> Automatic recognition of L2 speech-in-noise </h3>
											<p> In this study, we compared four state-of-the-art Automatic Speech Recognition (ASR) systems (<i>Google, HuBERT, wav2vec 2.0, whisper</i>) and human listeners on word recognition accuracy of second-language (L2) speech embedded in noise.
												We found that one system, <i>whisper</i>, performed at levels similar to (or in some cases, better than) human listeners.
												However, the content of its responses diverged substantially from human responses, when speech was embedded in high levels of noise.
												This suggests that ASR could be utilized to predict human intelligibility but should be used with caution. </p>
										</article>

										<!-- Research 3: F0 experiment -->
										<article>
											<a href="https://www.sciencedirect.com/science/article/pii/S0095447024000287" class="image"><img src="images/research_f0_length.png" alt="" /></a>
											<h3> Proactive and reactive F0 adjustments in speech </h3>
											<p> A production experiment was conducted to investigate speakers' (i) proactive and (ii) reactive F0 control.
											In particular, the experiment examined whether speakers vary F0 parameters (i) according to the initially planned utterance length and (ii) in response to the unanticipated changes in the length.
										  An experimental paradigm was developed in which the visual stimuli that cue the parts of the utterance are delayed until after participants initiate an utterance.
											Analyses of F0 trajectories found evidence for both proactive and reactive F0 control. </p>
											<!-- <ul class="actions">
												<li><a href="#" class="button">More</a></li>
											</ul> -->
										</article>

										<!-- Research 4: F0 model -->
										<article>
											<!-- <a href="pdfs/pdf_diss.pdf" class="image"><img src="images/research_f0_model.png" alt="" /></a> -->
											<a class="image"><img src="images/research_f0_model.png" alt="" /></a>
											<h3> The Gesture-Field-Register framework for modeling F0 control </h3>
											<p> This study proposed a modeling framework that accounts for speakers' pitch/F0 control, building on Articulatory Phonology and Task Dynamics. The framework considers F0 gestures to be the fundamental control units.
												The F0 gestures have normalized targets; at each time point, the targets of the gestures that are active and the forces of the neutral system determine the (normalized) dynamic target of the F0 tract variable.
												The dynamic targets are transformed to F0 values in Hz via F0 register parameters.
												By fitting empirical F0 data that span multiple phrases (with several F0 peaks/valleys), we found evidence in support of the control mechanism, where speakers have invariant F0 targets but variant F0 register.
												This suggests that speakers may be primarily adjusting their F0 space with relatively fixed F0 targets, in order to produce F0 variations within an utterance. </p>

											<!-- <p> The present study examined what speakers control most directly to produce variationa in F0, by evaluating <i>target</i>-control and <i>register</i>-control hypotheses.
											In the <i>target</i>-control hypothesis, it is individual pitch targets that speakers mainly control to produce variations in F0, whereas in the <i>register</i>-control hypothesis,
										  it is the control of pitch register (F0 space in which the targets are realized) that induces F0 variations.
											These hypotheses were assessed by examining the correlations between F0 peaks and valleys in empirical F0 trajectories and through computational modeling.
										  The results suggest that pitch register may be a more important control parameter than previous models have assumed. </p> -->
										</article>

										<!-- Research 5: speech rate -->
										<article>
											<a href="https://www.sciencedirect.com/science/article/pii/S0095447022000274" class="image"><img src="images/research_speech_rate.png" alt="" /></a>
											<h3> Functional relations between speech rate and phonetic variables </h3>
											<p> This study examined how phonetic measures covary with speech rate, specifically assessing whether there is evidence for linear and/or non-linear relations with rate, and how those relations may differ between phrase boundaries.
											Productions of English non-restrictive (NRRCs) and restrictive relative clauses (RRCs) were collected using a method in which variation in speech rate was cued by the speed of motion of a visual stimulus.
											Analyses of articulatory and acoustic variables showed that the variables associated with a phrase boundary that follows the RC were more susceptible to rate variation than those at a boundary that precedes the RC.
											Phonetic variables at the post-RC boundary also showed evidence for non-linear relations with rate, which suggest floor or ceiling attenuation effects at extreme rates.</p>
										</article>

										<!-- Research 6: localization -->
										<article>
											<a href="pdfs/pdf_localization.pdf" class="image"><img src="images/research_scalogram.png" alt="" /></a>
											<h3> Temporal localization of syntactic-prosodic information </h3>
											<p> This study used a novel neural network-based analysis method for temporally localizing prosodic information that is associated with syntactic contrast in acoustic and articulatory signals.
												Neural networks were trained on multi-dimensional acoustic and articulatory data to classify the two types of relative clauses (RRCs vs. NRRCs), and the network accuracies on test data were analyzed.
												The results found two different patterns: (i) syntactically conditioned prosodic information was either widely distributed around the boundaries or (ii) narrowly distributed at specific locations.
												The findings suggest that prosodic expression of syntactic contrasts does not occur in the uniform way or at a fixed location. </p>
										</article>

										<!-- Research 6: categorical evidence -->
										<!-- <article>
											<a href="pdfs/pdf_prosodic_categories.pdf" class="image"><img src="images/research_categorical.png" alt="" /></a>
											<h3> Phonetic evidence for hierarchical prosodic phrases </h3>
											<p> This study shows that the existing phonetic evidence for hierarchical organization of prosodic phrases is ambiguous, and that a non-hierarchical organization of phrases is also consistent with the data.
												To compare hierarchical and non-hierarchical organization models, the current study analyzed productions of English NRRCs and RRCs at varying speech rates.
												We examined whether articulatory and acoustic variables at phrase boundaries exhibit evidence of speech rate-dependent mixtures of categories through regression mixture models.
												Overall, the evidence for multiple levels of prosodic phrase categories was not very compelling. The measures that were most supportive of hierarchical phrase structure were measures of boundary-related slowing and gestural overlap at boundaries.</p>
										</article> -->

									</div>
								</section>


								<!-- Teaching Section -->
									<section>
										<header id="teaching" class="main special">
											<h1>Teaching</h1>
										</header>
										<div class="features">
											<article>
												<span class="icon fa-gem"></span>
												<div class="content">
													<h3> Introduction to Phonetics and Phonology </h3>
													<p> [Spring 2019] Department of Linguistics, Cornell University <br />
															Instructor: Draga Zec </p>
												</div>
											</article>
											<article>
												<span class="icon solid fa-paper-plane"></span>
												<div class="content">
													<h3> Elementary Korean I </h3>
													<p> [Fall 2018, 2019, 2020] Department of Asian Studies, Cornell University </p>
												</div>
											</article>
											<article>
												<span class="icon solid fa-rocket"></span>
												<div class="content">
													<h3> Elementary Korean II </h3>
													<p> [Spring 2022] Department of Asian Studies, Cornell University </p>
												</div>
											</article>
											<!-- <article>
												<span class="icon solid fa-signal"></span>
												<div class="content">
													<h3> Research Assistant </h3>
													<p> [Spring 2020] Department of Linguistics, Cornell University <br />
															PI: John B. Whitman </p>
												</div>
											</article> -->
										</div>
									</section>


						</div>
					</div>

				<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">

							<!-- Search -->
								<!-- <section id="search" class="alt">
									<form method="post" action="#">
										<input type="text" name="query" id="query" placeholder="Search" />
									</form>
								</section> -->

							<!-- Menu -->
								<nav id="menu">
									<header class="major">
										<h2>Menu</h2>
									</header>
									<ul>
										<li><a href=#banner>About Me</a></li>
										<li><a href="pdfs/CV_SK.pdf">CV</a></li>
										<li><a href=#research>Research</a></li>
										<li><a href=#teaching>Teaching</a></li>
										<!-- <li>
											<span class="opener">Submenu</span>
											<ul>
												<li><a href="#">Lorem Dolor</a></li>
												<li><a href="#">Ipsum Adipiscing</a></li>
												<li><a href="#">Tempus Magna</a></li>
												<li><a href="#">Feugiat Veroeros</a></li>
											</ul>
										</li> -->
									</ul>
								</nav>

							<!-- Section -->
								<section>
									<header class="major">
										<h2>Get in touch</h2>
									</header>
									<!-- <p>Sed varius enim lorem ullamcorper dolore aliquam aenean ornare velit lacus, ac varius enim lorem ullamcorper dolore. Proin sed aliquam facilisis ante interdum. Sed nulla amet lorem feugiat tempus aliquam.</p> -->
									<ul class="contact">
										<li class="icon solid fa-envelope"><a href = "mailto: seungeun.kim@northwestern.edu">seungeun.kim@northwestern.edu</a></li>
										<!-- <li class="icon solid fa-phone">(000) 000-0000</li> -->
										<li class="icon solid fa-home"> 2016 Sheridan Road <br />
										Evanston, IL 60208</li>
									</ul>
								</section>

							<!-- Footer -->
								<footer id="footer">
									<p class="copyright">&copy; Seung-Eun Kim <br /> Last updated: Mar 2024 <br />
										Design: <a href="https://html5up.net">HTML5 UP</a></p>
								</footer>

						</div>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
